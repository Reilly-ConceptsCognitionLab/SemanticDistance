[{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/articles/SemanticDistance.html","id":"install-package-and-load-library","dir":"Articles","previous_headings":"","what":"Install package and load library","title":"SemanticDistance","text":"","code":"#install.packages(\"devtools\") #to install devlopment version, run this #devtools::install_github(\"Reilly-ConceptsCognitionLab/ConversationAlign\") #installs from github library(SemanticDistance) #> Warning: replacing previous import 'magrittr::set_names' by 'purrr::set_names' #> when loading 'SemanticDistance' #> Warning: replacing previous import 'purrr::%@%' by 'rlang::%@%' when loading #> 'SemanticDistance' #> Warning: replacing previous import 'purrr::flatten_lgl' by 'rlang::flatten_lgl' #> when loading 'SemanticDistance' #> Warning: replacing previous import 'purrr::splice' by 'rlang::splice' when #> loading 'SemanticDistance' #> Warning: replacing previous import 'purrr::flatten_chr' by 'rlang::flatten_chr' #> when loading 'SemanticDistance' #> Warning: replacing previous import 'purrr::flatten_raw' by 'rlang::flatten_raw' #> when loading 'SemanticDistance' #> Warning: replacing previous import 'purrr::flatten' by 'rlang::flatten' when #> loading 'SemanticDistance' #> Warning: replacing previous import 'purrr::flatten_dbl' by 'rlang::flatten_dbl' #> when loading 'SemanticDistance' #> Warning: replacing previous import 'purrr::invoke' by 'rlang::invoke' when #> loading 'SemanticDistance' #> Warning: replacing previous import 'purrr::flatten_int' by 'rlang::flatten_int' #> when loading 'SemanticDistance' #> Warning: replacing previous import 'dplyr::lag' by 'stats::lag' when loading #> 'SemanticDistance' #> Warning: replacing previous import 'dplyr::filter' by 'stats::filter' when #> loading 'SemanticDistance' #> Warning: replacing previous import 'magrittr::extract' by 'tidyr::extract' when #> loading 'SemanticDistance'"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/articles/SemanticDistance.html","id":"semantic-distance-what-it-does--","dir":"Articles","previous_headings":"","what":"Semantic Distance: What it does..","title":"SemanticDistance","text":"Semantic Distance empirical measure similarity/distance two elements (words, ngrams, documents) within n-dimensional semantic space. MANY ways measure semantic distance. SemanticDistance package appends pairwise cosine distance values different chunks language chunk sizes specified user (e.g., word--word, ngram--word). package derives empirical distance values indexing two large lookup databases embedded within package. databases include fixed semantic vectors many English words. One measure (CosDist_Glo) reflects distance pairwise vectors (Dog:Leash) derived training GLOVE word embedding model (300 hyperparameters per word). complementary metric (CodDist_SD15) refects cosine distance two chunks (words, groups words) characterized across 15 meaningful perceptual affective dimensions (e.g., color, sound, valence). SemanticDistance cleans formats target text applying variety options (e.g., leave alone, clean punctuation, omit stopwords, lemmatize strings). package can handle variety dataframe formats, including ordered monologues, word pairs arrayed columns, unordered word lists, dialogue transcripts marked talker information. SemanticDistance scans cleaned/formatted dataframe computes two different metrics semantic distance successive chunks (e.g., ngrams, words, turns). two semantic distance values reflect pairwise cosine distance (0 2) two different high dimensional semantic spaces. Experiential semantic distance (SD15) reflects pairwise distance two word vectors (e.g., dog:cat) spanning 15 meaningful semantic dimensions (e.g., color, sound, valence). Embedding-based semantic distances (Glo) derived contrasting word’s semantic vector spanning 300 hyperparameters trained GLOVE word embedding model.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/articles/SemanticDistance.html","id":"step-1-clean-and-prep-your-text","dir":"Articles","previous_headings":"","what":"Step 1: Clean and Prep Your Text","title":"SemanticDistance","text":"SemanticDistance works monologues (talker information), dialogues (two speakers), word pairs arrayed columns, unstructured word lists (hierarchical clustering). Cleaning can even handle unstructured text pasted single cell csv file. However, MUST run appropriate cleaning function run distance functions even apply cleaning options. functions append unique identifiers used distance calculations. Prep string data (csv text) read R (e.g., myrawdat). Call objects variables anything like. SemanticDistance retain metadata. data contain least one column string data (e.g., mytext). Identify format sample (e.g., monologue, dialogue, columns, unstructured). Decide cleaning parameters (lemmatize, omit stopwords, omit punctuation). Specify cleaning function arguments best fit aims.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/articles/SemanticDistance.html","id":"monologue-transcript-clean_monologue","dir":"Articles","previous_headings":"Step 1: Clean and Prep Your Text","what":"Monologue Transcript (clean_monologue)","title":"SemanticDistance","text":"story etc. - basically string word order matters don’t care talker information. target text split unlisted one word per row format.metadata retained. ’s sample monologue sorts junk column called ‘word’. ‘clean_monologue’ function split append unique identifier word retaining empty strings meaningful. Defaults omit stopwords lemmatize.","code":""},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/articles/SemanticDistance.html","id":"step-2-compute-semantic-distance-on-your-prepped-data","dir":"Articles","previous_headings":"","what":"Step 2: Compute Semantic Distance on your Prepped Data","title":"SemanticDistance","text":"SemanticDistance append cosine distance values pair elements specified user (e.g., word--word, ngram--word). distance values derived two large lookup databases package fixed semantic vectors >70k English words. CosDist_Glo reflects cosine distance vectors derived training GLOVE word embedding model (300 hyperparameters per word). CodDist_SD15 refects cosine distance two chunks (words, groups words) characterized across 15 meaningful perceptual affective dimensions (e.g., color, sound, valence). Users specify ngram window size. window rolls successively language sample compute semantic distance value new word relative n-words (ngram size) . model compouting distance illustrated figure. larger specified ngram size smoothed semantic vector language sample. settle window size clean language transcript (works monologues ), ready roll. ’s general idea…","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/articles/SemanticDistance.html","id":"monologues-ngram-to-ngram-distance-dist_ngram2ngram","dir":"Articles","previous_headings":"Step 2: Compute Semantic Distance on your Prepped Data","what":"2.2: Monologues: Ngram-to-Ngram Distance (dist_ngram2ngram)","title":"SemanticDistance","text":"Joins target transcript lookup database word corresponding semantic vector row form. example, interested 4-word chunks, dog-cat-milk-banana (Ngram_4) first ngram. aggregate semantic vectors four words mean vector 4-gram compute distance next 4-gram iterating dataframe last possible chunk four words omitting ‘leftovers’ (residual/remainder divisible ngram size). example 22 words user interested 3-grams, 7 one word left last row.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Jamie Reilly. Author, maintainer. Emily B. Myers. Author. Hannah R. Mechtenberg. Author. Jonathan E. Peelle. Author.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Reilly J, Myers E, Mechtenberg H, Peelle J (2025). SemanticDistance: Compute Visualize Pairwise Semantic Distance Relationships Ordered Unordered Language Samples. R package version 0.1.0, https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance.","code":"@Manual{,   title = {SemanticDistance: Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples},   author = {Jamie Reilly and Emily B. Myers and Hannah R. Mechtenberg and Jonathan E. Peelle},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance}, }"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"data-compatibility","dir":"","previous_headings":"","what":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"SemanticDistance can compute pairwise semantic distance relationships ordered unordered language samples, including: Monologues: ordered text sample delineated talker/speaker (e.g., stories, narratives). minimal requirement monologue one row one column text .; Dialogues: ordered language sample split talker/speaker/interlocutor factor. minimum requirment two cells interlocutor identity text; Word Pairs Columns: Paired string data arrayed across two columns (e.g., Dog-Leash); Unordered Word Lists: Unordered list words (nominally one column, text one row) transformed distance matrix, network model, dendrogram","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"prep-and-analyze-your-data","dir":"","previous_headings":"","what":"Prep and Analyze Your Data","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Store text project files within dedicated folder/directory (e.g., ‘mytexts/’) Format data CSV txt. Although SemanticDistance fairly robust different character encodings, many proograms Excel introduce weird hidden characters strings. Label target text metadata columns offline however like (e.g., mytext, word, langoutput) Import text associated metadata (e.g., document_id, timestamps, etc.) dataframe. Identify format sample (e.g., monologue, dialogue, columns, unstructured). Install load SemanticDistance package Choose principled set cleaning parameters (e.g., omit stopwords? lemmatize?) Run approproate cleaning function best fits data stucture aims Run appropriate distance function best fits data stucture aims Visualize data using built-functions follow-preferred statistical approach. Install development version SemanticDistance GitHub using devtools.","code":"#install.packages(\"devtools\") #devtools::install_github(\"Reilly-ConceptsCognitionLab/SemanticDistance\") library(SemanticDistance)"},{"path":[]},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"id_-clean-monologue-transcript-clean_monologue-","dir":"","previous_headings":"","what":"Clean Monologue Transcript (clean_monologue)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Transforms text lowercase optionally cleans (omit stopwords, omit non-alphabetic chars), lemmatizes (transforms morphological derivatives words standard dictionary entries), splits multiword utreerances one-word-per row format. can generally leave split_strings default state (TRUE). ‘clean_monologue’ appends several new variables original dataframe: id_row_orig numeric identifier marking original row word group words appeared; ’id_row_postsplit unique identifier marking word’s ordered position dataframe splitting multiword utterances across rows; word_clean result cleaning operations, needed distance calculations. Arguments ‘clean_monologue’: dat = raw dataframe least one column text wordcol = quoted variable column name target text lives (e.g., ‘mytext’) clean = applies cleaning functions (e.g., punct , lowercase, etc); T/F default TRUE omit_stops = omits stopwords, T/F default TRUE lemmatize = transforms raw word lemmatized form, T/F default TRUE split_strings = option split multiword utterances separate rows, T/F default TRUE","code":"Monologue_Cleaned <- clean_monologue(dat=Monologue_Structured, wordcol='mytext', clean=TRUE, omit_stops=TRUE, split_strings=TRUE) head(Monologue_Cleaned, n=8) #> # A tibble: 8 × 5 #>   id_row_orig word_clean timestamp mytext   id_row_postsplit #>   <fct>       <chr>          <int> <chr>               <int> #> 1 1           <NA>               1 \"the\"                   1 #> 2 2           girl               2 \"girl\"                  2 #> 3 3           walk               3 \"walked\"                3 #> 4 4           down               4 \"down \"                 4 #> 5 5           <NA>               5 \"the \"                  5 #> 6 6           street             6 \"street\"                6 #> 7 7           <NA>               7 \"the\"                   7 #> 8 8           boxer              8 \"boxer\"                 8"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"option-1-ngram-to-word-distance-dist_ngram2word-","dir":"","previous_headings":"","what":"Option 1: Ngram-to-Word Distance (dist_ngram2word)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Computes cosine distance two models (embedding experiential) using rolling ngram approach consisting groups words (ngrams) next word. IMPORTANT function rolls backward target word skipping NAs filling desired ngram size. Arguments ‘dist_ngram2word’: dat = dataframe monologue transcript cleaned prepped clean_monologue fn ngram = window size preceding new content word, ngram=1 means word compared word ","code":"Ngram2Word_Dists1 <- dist_ngram2word(dat=Monologue_Cleaned, ngram=1) #distance word-to-word head(Ngram2Word_Dists1) #> # A tibble: 6 × 7 #>   id_row_orig word_clean timestamp mytext   id_row_postsplit CosDist_1gram_glo #>   <fct>       <chr>          <int> <chr>               <int>             <dbl> #> 1 1           <NA>               1 \"the\"                   1            NA     #> 2 2           girl               2 \"girl\"                  2            NA     #> 3 3           walk               3 \"walked\"                3             0.470 #> 4 4           down               4 \"down \"                 4             0.283 #> 5 5           <NA>               5 \"the \"                  5            NA     #> 6 6           street             6 \"street\"                6             0.362 #> # ℹ 1 more variable: CosDist_1gram_sd15 <dbl>"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"option-2-ngram-to-ngram-distance-dist_ngram2ngram","dir":"","previous_headings":"","what":"Option 2: Ngram-to-Ngram Distance (dist_ngram2ngram)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"User specifies n-gram size (e.g., ngram=2). Distance computed two-word chunk next iterating way dataframe words ‘fill ’ last ngram. Note distance function works monologue transcripts speakers delineated word order matters. Arguuments ‘dist_ngram2ngram’: dat = dataframe w/ monologue sample cleaned prepped ngram = chunk size (chunk--chunk), case ngram=2 means chunks 2 words compared next chunk","code":"Ngram2Ngram_Dist1 <- dist_ngram2ngram(dat=Monologue_Cleaned, ngram=2) head(Ngram2Ngram_Dist1) #> # A tibble: 6 × 7 #>   id_row_orig word_clean timestamp mytext   id_row_postsplit CosDist_2gram_GLO #>   <fct>       <chr>          <int> <chr>               <int>             <dbl> #> 1 1           <NA>               1 \"the\"                   1           NA      #> 2 2           girl               2 \"girl\"                  2           NA      #> 3 3           walk               3 \"walked\"                3           NA      #> 4 4           down               4 \"down \"                 4            0.141  #> 5 5           <NA>               5 \"the \"                  5            0.0608 #> 6 6           street             6 \"street\"                6            0.319  #> # ℹ 1 more variable: CosDist_2gram_SD15 <dbl>"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"option-3-anchor-to-word-distance-dist_anchor2word","dir":"","previous_headings":"","what":"Option 3: Anchor-to-Word Distance (dist_anchor2word)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Models semantic distance successive new word average semantic vectors first block N content words. anchored distance provides metric overall semantic drift language sample unfolds relative fixed starting point. Arguments ‘dist_anchor’: dat = dataframe monologue sample cleaned prepped using ‘clean_monologue’ anchor_size = size initial chunk words chunk--new-word comparisons fn","code":"Anchored_Dists1 <- dist_anchor(dat=Monologue_Cleaned, anchor_size=8) head(Anchored_Dists1) #> # A tibble: 6 × 4 #>   id_row_postsplit word_clean CosDist_Anchor_GLO CosDist_Anchor_SD15 #>              <int> <chr>                   <dbl>               <dbl> #> 1                1 <NA>                   NA                 NA      #> 2                2 girl                    0.255              0.439  #> 3                3 walk                    0.159              0.173  #> 4                4 down                    0.116              0.275  #> 5                5 <NA>                   NA                 NA      #> 6                6 street                  0.116              0.0457"},{"path":[]},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"clean-dialogue-transcript-clean_dialogue","dir":"","previous_headings":"","what":"Clean Dialogue Transcript (clean_dialogue)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"conversation transcript language sample care talker/interlocutor information (e.g., computing semantic distance across turns conversation). dataframe nominally contain text column speaker/talker column. Arguments ‘clean_dialogue’ : dat = raw dataframe least one column text talker column wordcol = column name (quoted) containing text want cleaned whotalks = column name (quoted) containing talker ID (convert factor) clean = applies cleaning function, T/F default TRUE omit_stops = omits stopwords, T/F default TRUE lemmatize = transforms raw word lemmatized form, T/F default TRUE","code":"Dialogue_Cleaned <- clean_dialogue(dat=Dialogue_Structured, wordcol=\"mytext\", whotalks = \"speaker\", clean=TRUE, omit_stops=TRUE, lemmatize=TRUE, split_strings=TRUE) head(Dialogue_Cleaned, n=12) #> # A tibble: 12 × 7 #>    id_row_orig word_clean mytext    speaker talker id_row_postsplit id_turn #>    <fct>       <chr>      <chr>     <chr>   <fct>             <int>   <dbl> #>  1 1           donkey     donkey    P1      P1                    1       1 #>  2 2           astronaut  astronaut P2      P2                    2       2 #>  3 3           bubble     bubble    P1      P1                    3       3 #>  4 4           street     street    P2      P2                    4       4 #>  5 5           pigeon     Pigeon    P1      P1                    5       5 #>  6 6           dolphin    Dolphin   P2      P2                    6       6 #>  7 7           eagle      Eagle     P1      P1                    7       7 #>  8 8           eel        eel       P2      P2                    8       8 #>  9 9           test       test      P1      P1                    9       9 #> 10 10          beagle     Beagle    P2      P2                   10      10 #> 11 11          cow        Cow       P1      P1                   11      11 #> 12 12          tiger      Tiger     P2      P2                   12      12"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"id_-dialogue-distance-turn-to-turn-dist_dialogue","dir":"","previous_headings":"","what":"Dialogue Distance Turn-to-Turn (dist_dialogue)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Averages semantic vectors content words turn computes cosine distance average semantic vectors content words subsequent turn. Note: function works dialogue samples marked talker variable (e.g., conversation transcripts). averages across semantic vectors words within turn computes cosine distance words next turn. just need feed transcript formatted clean_dialogue. ‘dist_dialogue’ return summary dataframe distance values aggregated talker turn (id_turn). Arguments ‘dist_dialogue’: dat = dataframe w/ dialogue sample cleaned prepped using ‘clean_dialogue’","code":"#DialogueDists <- dist_dialogue(dat=Dialogue_Cleaned) #head(DialogueDists)"},{"path":[]},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"id_-clean-word-pairs-clean_paired_cols-","dir":"","previous_headings":"","what":"Clean Word Pairs (clean_paired_cols)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"SemanticDistance also computes pairwise distance data arrayed columns. Run function, cleaned columns appear dataframe. Arguments ‘clean_paired_cols’: dat = raw dataframe two columns paired text word1 = quoted variable reflecting column name first word lives word2 = quoted variable reflecting column name first word lives clean = applies cleaning functions, T/F default TRUE omit_stops = omits stopwords, T/F default TRUE lemmatize = transforms raw word lemmatized form, T/F default TRUE","code":"WordPairs_Clean <- clean_paired_cols(dat=Word_Pairs, wordcol1='word1', wordcol2='word2', clean=TRUE, omit_stops=TRUE, lemmatize=TRUE) head(WordPairs_Clean, n=12) #view head cleaned data #>    word1     word2 id_row_orig word1_clean1 word2_clean2 #> 1    Dog   trumpet           1          dog      trumpet #> 2    the    BANANA           2         <NA>       banana #> 3    rat astronaut           3          rat    astronaut #> 4   *&^%    lizard           4         <NA>       lizard #> 5   bird      bird           5         bird         bird #> 6  shark     shark           6        shark        shark #> 7  table     38947           7        table         <NA> #> 8    Dog     leash           8          dog        leash #> 9    cat       fur           9          cat          fur #> 10     ^     whale          10         <NA>        whale #> 11 steak    potato          11        steak       potato #> 12   bed    pillow          12          bed       pillow"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"distance-word-pairs-columns-dist_paired_cols-","dir":"","previous_headings":"","what":"Distance Word Pairs Columns (dist_paired_cols)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Generates semantic distances (Glove SD15) word pairs separate columns. Output ‘dist_paired_cols’ 2-column arrayed dataframe. Arguments dist_paired_cols: Arguments ‘dist_paired_cols’: dat = dataframe w/ word pairs arrayed columns cleaned prepped using ‘clean_2cols’ fn","code":"Columns_Dists <- dist_paired_cols(WordPairs_Clean) #only argument is dataframe head(Columns_Dists) #>   word1     word2 id_row_orig word1_clean1 word2_clean2 CosDist_SD15 #> 1   Dog   trumpet           1          dog      trumpet    0.4534507 #> 2   the    BANANA           2         <NA>       banana           NA #> 3   rat astronaut           3          rat    astronaut    1.2154729 #> 4  *&^%    lizard           4         <NA>       lizard           NA #> 5  bird      bird           5         bird         bird    0.0000000 #> 6 shark     shark           6        shark        shark    0.0000000 #>   CosDist_GLO #> 1   0.8409885 #> 2          NA #> 3   0.9272540 #> 4          NA #> 5   0.0000000 #> 6   0.0000000"},{"path":[]},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"clean-unordered-word-list-clean_unordered","dir":"","previous_headings":"","what":"Clean unordered word list (clean_unordered)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Prep vector words hierarchical clustering network visualization. ‘clean_unordered’ retain one instance string (distinct, duplicates) missing values. Arguments ‘clean_unordered’: df = raw dataframe least one column text wordcol = quoted variable reflecting text lives clean = applies cleaning functions, T/F default TRUE omit_stops = omits stopwords, T/F default TRUE lemmatize = transforms raw word lemmatized form, T/F default TRUE","code":"Clusters_Clean <- clean_unordered(dat=Semantic_Clusters, wordcol=\"mytext\", clean=TRUE, omit_stops=TRUE, lemmatize=TRUE) head(Clusters_Clean) #> # A tibble: 6 × 6 #>   id_row_orig word_clean ID_JR mytext   category id_row_postsplit #>   <fct>       <chr>      <int> <chr>    <chr>               <int> #> 1 1           trumpet        1 trumpet  music                   1 #> 2 2           trombone       2 trombone music                   2 #> 3 3           flute          3 flute    music                   3 #> 4 4           piano          4 piano    music                   4 #> 5 5           guitar         5 guitar   music                   5 #> 6 6           gun            6 gun      weapon                  6"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"distance-matrix-all-word-pairs-dist_matrix","dir":"","previous_headings":"","what":"Distance Matrix All Word Pairs (dist_matrix)","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Returns square matrix entry [,j] cosine distance word word j. Matrix contains original words row column names reference. User specifies whether return matrix based embeddings (GLOVE) experiential norms (SD15). Arguments ‘dist_matrix’: dat = dataframe cleaned prepped using ‘clean_unordered4matrix’ fndist_type = quoted argument default ‘embedding’, option “SD15” fn","code":"MyDistMatrix <- dist_matrix(dat=Clusters_Clean, dist_type='embedding') MyDistMatrix[1:7, 1:7] #Print columns 1:7, rows 1:7 square matrix #>            trumpet  trombone     flute     piano    guitar       gun     knife #> trumpet  0.0000000 0.5717885 0.5138417 0.5558156 0.5520448 0.8668525 0.8766921 #> trombone 0.5717885 0.0000000 0.6698538 0.6488034 0.6219389 0.9475109 0.8880578 #> flute    0.5138417 0.6698538 0.0000000 0.4511922 0.5203509 0.9288003 0.8349393 #> piano    0.5558156 0.6488034 0.4511922 0.0000000 0.2730333 0.8374068 0.7856145 #> guitar   0.5520448 0.6219389 0.5203509 0.2730333 0.0000000 0.7653835 0.7351402 #> gun      0.8668525 0.9475109 0.9288003 0.8374068 0.7653835 0.0000000 0.5440601 #> knife    0.8766921 0.8880578 0.8349393 0.7856145 0.7351402 0.5440601 0.0000000"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"step-3-distance-matrix-to-hclust","dir":"","previous_headings":"","what":"Step 3: Distance Matrix to HClust","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"","code":"#TBD"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"data-visualization-options","dir":"","previous_headings":"","what":"–DATA VISUALIZATION OPTIONS–","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Choose visualization strategy best fits data. ordered? monologue? interested chunk--chunk distance distance new element fixed anchor beginning? three options explained follow:","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"monologue-time-series-ngram2word","dir":"","previous_headings":"","what":"Monologue Time Series: ngram2word","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Plots word id_row x-axis (proxy time) distance measure (facetted GLO SD15). Add red line annotation semantic distance jump z>3 based distribution time series, Add options interpolation rolling average window, zscore threshold marking annotation Arguments ‘viz_monologue’: dat dataframe CosDist values row_id_postsplit vars appended interpolate T/F linear interpolation option across missing observations row, default TRUE roll_avg rolling average window size, default 0 facet T/F option facet cosine distance type, default TRUE annotate T/F option append annotations (red lines z>2.5 distance jump), default TRUE","code":"clusters_clean <- clean_monologue(dat=Semantic_Clusters, wordcol='mytext', clean=TRUE, omit_stops=TRUE, split_strings=TRUE) clusters_dist <- dist_ngram2word(dat=clusters_clean, ngram=1)  FirstViz <- viz_monologue(dat=clusters_dist, interpolate=TRUE, roll_avg=0, facet=TRUE, annotate=TRUE) #> Warning: Using one column matrices in `filter()` was deprecated in dplyr 1.1.0. #> ℹ Please use one dimensional logical vectors instead. #> ℹ The deprecated feature was likely used in the SemanticDistance package. #>   Please report the issue at #>   <https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/issues>. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated. print(FirstViz) #> Warning: Removed 2 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"monologue-time-series-dist_anchor","dir":"","previous_headings":"","what":"Monologue Time Series: dist_anchor","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"story","code":"grandpa_clean <- clean_monologue(dat=Grandfather_Passage, wordcol='mytext', clean=TRUE, omit_stops=TRUE, split_strings=TRUE) grandpa_dist <- dist_anchor(grandpa_clean, anchor_size=8)  AnchorViz <- viz_monologue(dat=grandpa_dist, interpolate=TRUE, roll_avg=0, facet=TRUE, annotate=TRUE) print(AnchorViz) #> Warning: Removed 2 rows containing missing values or values outside the scale range #> (`geom_line()`)."},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"time-series-plot-for-dialogues","dir":"","previous_headings":"","what":"Time series plot for dialogues","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Color point talker","code":"#TBA"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"semantic-clusters","dir":"","previous_headings":"","what":"Semantic Clusters","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"unordered list, triangle dendrogram","code":"#TBA"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"semantic-network","dir":"","previous_headings":"","what":"Semantic network","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"Simple igraph network (undirected) unordered list #Animate Time Series","code":"#TBA #TBA"},{"path":[]},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/index.html","id":"sample-language-transcripts","dir":"","previous_headings":"","what":"Sample Language Transcripts","title":"Compute and Visualize Pairwise Semantic Distance Relationships in Ordered and Unordered Language Samples","text":"SemanticDistance contains sample language transcripts automatically load call package. can helpful evaluating debugging transcripts. Monologue_Structured: Dataframe 1-word per row already split missing observations Monologue_Messy: Dataframe text arrayed one column ‘mytext’, missing observations, junk, multiword phrases contains metadata (simulated timestamps Dialogue_Structured: Dataframe simulating ‘perfect’ conversation transcript, one word per turn, two talkers Dialogue_Messy: Dataframe simulating ‘dirty’ conversation transcript, multiple lines per person, lots stopwords, missing obervations, stray transcription symbols Word_Pairs: Dataframe word pairs arrayed two columns Semantic_Clusters: Dataframe ordered simulated semantic fluency data switching categories every ten words (animals, tools, musical instruments, fruits) Grandfather_Passage: Grandfather Passage – standardized reading passage, unsplit","code":"head(Monologue_Structured) #>   timestamp mytext #> 1         1    the #> 2         2   girl #> 3         3 walked #> 4         4  down  #> 5         5   the  #> 6         6 street head(Monologue_Messy) #>              mytext #> 1  The dog is blue. #> 2               Dog #> 3               Dog #> 4              Some #> 5 My name is Frank. #> 6               Dog head(Dialogue_Structured) #>      mytext speaker #> 1    donkey      P1 #> 2 astronaut      P2 #> 3    bubble      P1 #> 4    street      P2 #> 5    Pigeon      P1 #> 6   Dolphin      P2 head(Dialogue_Messy) #>                  word speaker #> 1            Hi Peter    Mary #> 2    Donkeys are gray    Mary #> 3             Leopard    Mary #> 4 pop goes the weasel    Mary #> 5              Pigeon    Mary #> 6             Dolphin    Mary head(Word_Pairs) #>   word1     word2 #> 1   Dog   trumpet #> 2   the    BANANA #> 3   rat astronaut #> 4  *&^%    lizard #> 5  bird      bird #> 6 shark     shark head(Semantic_Clusters, n=20) #>    ID_JR     mytext  category #> 1      1    trumpet     music #> 2      2   trombone     music #> 3      3      flute     music #> 4      4      piano     music #> 5      5     guitar     music #> 6      6        gun    weapon #> 7      7      knife    weapon #> 8      8    missile    weapon #> 9      9     bullet    weapon #> 10    10      spear    weapon #> 11    11      apple fruit-veg #> 12    12     banana fruit-veg #> 13    13     potato fruit-veg #> 14    14     tomato fruit-veg #> 15    15       kiwi fruit-veg #> 16    16        sad  emotions #> 17    17      happy  emotions #> 18    18      angry  emotions #> 19    19 melancholy  emotions #> 20    20     joyful  emotions GP <- tidyr::separate_rows(Grandfather_Passage, mytext, sep=\" \") print(GP) #> # A tibble: 129 × 1 #>    mytext       #>    <chr>        #>  1 You          #>  2 wish         #>  3 to           #>  4 know         #>  5 about        #>  6 my           #>  7 grandfather. #>  8 Well,        #>  9 he           #> 10 is           #> # ℹ 119 more rows"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Dialogue_Messy.html","id":null,"dir":"Reference","previous_headings":"","what":"Messy Dialogue Transcript — Dialogue_Messy","title":"Messy Dialogue Transcript — Dialogue_Messy","text":"sample dyadic conversation transcript two people taslking; Messy string data conversation tramscript, mulyiple lines per person per turn, missing observations, fragments, punctuations interspersed single words. Two people talking .","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Dialogue_Messy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Messy Dialogue Transcript — Dialogue_Messy","text":"","code":"Dialogue_Messy"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Dialogue_Messy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Messy Dialogue Transcript — Dialogue_Messy","text":"## \"Dialogue_Messy\" data frame 75 rows 2 columns: word text language transcript speaker Mary Peter: fictional speaker identities","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Dialogue_Structured.html","id":null,"dir":"Reference","previous_headings":"","what":"Dialogue Transcript Perfectly Formatted — Dialogue_Structured","title":"Dialogue Transcript Perfectly Formatted — Dialogue_Structured","text":"Perfectly pre-fomrmatted data structure 2 people coversing 1-word utterances back forth.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Dialogue_Structured.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Dialogue Transcript Perfectly Formatted — Dialogue_Structured","text":"","code":"Dialogue_Structured"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Dialogue_Structured.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Dialogue Transcript Perfectly Formatted — Dialogue_Structured","text":"## \"Dialogue_Structured\" data frame 50 rows 2 vars: mytext text language transcript speaker P1 P2 fictional interlocutor identities","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Grandfather_Passage.html","id":null,"dir":"Reference","previous_headings":"","what":"The Grandfather Passage: A Standardized Reading Passage — Grandfather_Passage","title":"The Grandfather Passage: A Standardized Reading Passage — Grandfather_Passage","text":"monologue discourse sample. Grandfather Passage well-known test reading aloud.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Grandfather_Passage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Grandfather Passage: A Standardized Reading Passage — Grandfather_Passage","text":"","code":"Grandfather_Passage"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Grandfather_Passage.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"The Grandfather Passage: A Standardized Reading Passage — Grandfather_Passage","text":"## \"Grandfather_Passage\" data frame 1 observation 1 variable: mytext text Grandfather Passage unsplit","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Monologue_Messy.html","id":null,"dir":"Reference","previous_headings":"","what":"A Sample Messy Monologue Transcript — Monologue_Messy","title":"A Sample Messy Monologue Transcript — Monologue_Messy","text":"talker delineated. Messy string data composed missing observations, fragments, punctuations interspersed single words.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Monologue_Messy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A Sample Messy Monologue Transcript — Monologue_Messy","text":"","code":"Monologue_Messy"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Monologue_Messy.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A Sample Messy Monologue Transcript — Monologue_Messy","text":"## \"Monologue_Messy\" data.frame 74 obs 1 var mytext text hypothetical language transcript","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Monologue_Structured.html","id":null,"dir":"Reference","previous_headings":"","what":"A Sample Structured Monologue Transcript — Monologue_Structured","title":"A Sample Structured Monologue Transcript — Monologue_Structured","text":"talker delineated. Idealized/structured transcript missing observations, fragments, multiword utterances, already split one-word-per-row","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Monologue_Structured.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A Sample Structured Monologue Transcript — Monologue_Structured","text":"","code":"Monologue_Structured"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Monologue_Structured.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"A Sample Structured Monologue Transcript — Monologue_Structured","text":"## \"Monologue_Structured\" data.frame 25 obs, 2 vars: mytext text hypothetical 'ideal' language transcript timestamp simulated metadata timestamp","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Semantic_Clusters.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Semantic Category Fluency Data: Word List Blocked by Semantic Category — Semantic_Clusters","title":"Simulated Semantic Category Fluency Data: Word List Blocked by Semantic Category — Semantic_Clusters","text":"talker delineated. Vector 20 words, 5 4 categories, Good examining clustering","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Semantic_Clusters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Semantic Category Fluency Data: Word List Blocked by Semantic Category — Semantic_Clusters","text":"","code":"Semantic_Clusters"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Semantic_Clusters.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Simulated Semantic Category Fluency Data: Word List Blocked by Semantic Category — Semantic_Clusters","text":"## \"Semantic_Clusters\" data frame 20 rows 3 columns: ID_JR sequential numeric identifier word target text category semantic category target word","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Word_Pairs.html","id":null,"dir":"Reference","previous_headings":"","what":"Column Arrayed Word Pairs for Pairwise Distance — Word_Pairs","title":"Column Arrayed Word Pairs for Pairwise Distance — Word_Pairs","text":"first target word computing distance one column, second word another column.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Word_Pairs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Column Arrayed Word Pairs for Pairwise Distance — Word_Pairs","text":"","code":"Word_Pairs"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/Word_Pairs.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Column Arrayed Word Pairs for Pairwise Distance — Word_Pairs","text":"## \"Word_Pairs\" data frame 27 rows 2 columns: word1 text corresponding first word pair contrast word2 text corresponding second word pair contrast","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_dialogue.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_dialogue — clean_dialogue","title":"clean_dialogue — clean_dialogue","text":"Cleans transcript two talkers. User specifies dataframe column name target text stored arguments function. Default option lemmatize strings. Function splits unlists text output one-row-per-word format marked unique numeric identifier (.e., 'id_orig')","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_dialogue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_dialogue — clean_dialogue","text":"","code":"clean_dialogue(   dat,   wordcol,   whotalks,   clean = TRUE,   omit_stops = TRUE,   lemmatize = TRUE,   split_strings = TRUE )"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_dialogue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean_dialogue — clean_dialogue","text":"dat datataframe least one target column string data wordcol quoted column name storing strings cleaned split whotalks quoted column name speaker/talker identities factorized clean T/F apply cleaning transformations (default TRUE) omit_stops T/F user wishes remove stopwords (default TRUE) lemmatize T/F user wishes lemmatize string (default TRUE) split_strings option T/F (default T) split multiword contractions separate rows","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_dialogue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"clean_dialogue — clean_dialogue","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_monologue.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_monologue — clean_monologue","title":"clean_monologue — clean_monologue","text":"Cleans formats text. User specifies dataframe column name target text stored arguments function. Default option lemmatize strings. Function splits unlists text output one-row-per-word format marked unique numeric identifier (.e., 'id_orig')","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_monologue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_monologue — clean_monologue","text":"","code":"clean_monologue(   dat,   wordcol,   clean = TRUE,   omit_stops = TRUE,   lemmatize = TRUE,   split_strings = TRUE )"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_monologue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean_monologue — clean_monologue","text":"dat dataframe least one target column string data wordcol quoted column name storing strings cleaned split clean apply cleaning functions (lowercase etc) default TRUE omit_stops option omitting stopwords default TRUE lemmatize option lemmatizing strings default TRUE split_strings option T/F (default T) split multiword utterances separate rows","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_monologue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"clean_monologue — clean_monologue","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_paired_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_paired_cols — clean_paired_cols","title":"clean_paired_cols — clean_paired_cols","text":"Cleans transcript word pairs arrayed two columns.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_paired_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_paired_cols — clean_paired_cols","text":"","code":"clean_paired_cols(   dat,   wordcol1,   wordcol2,   clean = TRUE,   omit_stops = TRUE,   lemmatize = TRUE )"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_paired_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean_paired_cols — clean_paired_cols","text":"dat dataframe two columns words want pairwise distance wordcol1 quoted column name storing first string comparison wordcol2 quoted column name storing second string comparison clean T/F default T specifies whether apply cleaning transformations leave data alone omit_stops T/F user wishes remove stopwords (default TRUE) lemmatize T/F user wishes lemmatize string (default TRUE)","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_paired_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"clean_paired_cols — clean_paired_cols","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_unordered.html","id":null,"dir":"Reference","previous_headings":"","what":"clean_unordered — clean_unordered","title":"clean_unordered — clean_unordered","text":"Cleans formats text. User specifies dataframe column name target text stored. Word order matter (words shuffled later). Cleaning takes first instance word.","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_unordered.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clean_unordered — clean_unordered","text":"","code":"clean_unordered(   dat,   wordcol,   clean = TRUE,   omit_stops = TRUE,   lemmatize = TRUE,   split_strings = TRUE )"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_unordered.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clean_unordered — clean_unordered","text":"dat dataframe least one target column string data wordcol quoted column name storing strings cleaned split clean apply cleaning functions (lowercase etc) default TRUE omit_stops option omitting stopwords default TRUE lemmatize option lemmatizing strings default TRUE split_strings option splitting multiple words one row across rows default TRUE","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/clean_unordered.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"clean_unordered — clean_unordered","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_anchor.html","id":null,"dir":"Reference","previous_headings":"","what":"dist_anchor — dist_anchor","title":"dist_anchor — dist_anchor","text":"Function takes dataframe cleaned using 'clean_monologue', computes rolling chunk--chunk distance user-specified ngram size (e.g., 2-word chunks)","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_anchor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dist_anchor — dist_anchor","text":"","code":"dist_anchor(dat, anchor_size = 10)"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_anchor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dist_anchor — dist_anchor","text":"dat dataframe prepped using 'clean_monologue' fn anchor_size integer specifying number words initial chunk comparison new words sample unfolds","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_anchor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dist_anchor — dist_anchor","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_dialogue.html","id":null,"dir":"Reference","previous_headings":"","what":"dist_dialogue — dist_dialogue","title":"dist_dialogue — dist_dialogue","text":"Function takes dataframe cleaned using 'clean_dialogue' computes two metrics semantic distance turn--turn indexing 'talker' column. Sums respective semantic vectors within tuern, cosine distance next turn's composite vector","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_dialogue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dist_dialogue — dist_dialogue","text":"","code":"dist_dialogue(dat)"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_dialogue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dist_dialogue — dist_dialogue","text":"dat dataframe prepped using 'clean_dialogue' fn talker data turncount appended","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_dialogue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dist_dialogue — dist_dialogue","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"dist_matrix — dist_matrix","title":"dist_matrix — dist_matrix","text":"Function takes dataframe cleaned using 'clean_unordered4matrix', pairwise distance elements matrix","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dist_matrix — dist_matrix","text":"","code":"dist_matrix(dat, dist_type = \"embedding\")"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dist_matrix — dist_matrix","text":"dat dataframe prepped using 'clean_unordered4matrix' fn dist_type semantic norms running distance matrix default='embedding', 'SD15'","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dist_matrix — dist_matrix","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_ngram2ngram.html","id":null,"dir":"Reference","previous_headings":"","what":"dist_ngram2ngram — dist_ngram2ngram","title":"dist_ngram2ngram — dist_ngram2ngram","text":"Function takes dataframe cleaned using 'clean_monologue', computes rolling chunk--chunk distance user-specified ngram size (e.g., 2-word chunks)","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_ngram2ngram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dist_ngram2ngram — dist_ngram2ngram","text":"","code":"dist_ngram2ngram(dat, ngram)"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_ngram2ngram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dist_ngram2ngram — dist_ngram2ngram","text":"dat dataframe prepped using 'clean_monologue' fn ngram integer specifying window size words computing distance target word","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_ngram2ngram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dist_ngram2ngram — dist_ngram2ngram","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_ngram2word.html","id":null,"dir":"Reference","previous_headings":"","what":"dist_ngram2word — dist_ngram2word","title":"dist_ngram2word — dist_ngram2word","text":"Function takes dataframe cleaned using 'clean_monologue', computes two metrics semantic distance word relative average semantic vectors within n-word window appearing word. User specifies window (ngram) size. window 'rolls' across language sample providing distance metrics","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_ngram2word.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dist_ngram2word — dist_ngram2word","text":"","code":"dist_ngram2word(dat, ngram)"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_ngram2word.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dist_ngram2word — dist_ngram2word","text":"dat dataframe prepped using 'clean_monologue' fn ngram integer specifying window size words computing distance target word go back skipping NAs content words equals ngram window","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_ngram2word.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dist_ngram2word — dist_ngram2word","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_paired_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"dist_paired_cols — dist_paired_cols","title":"dist_paired_cols — dist_paired_cols","text":"Function takes dataframe cleaned using 'clean_2columns', computes two metrics semantic distance word pair arrayed Col1 vs. Col2","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_paired_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dist_paired_cols — dist_paired_cols","text":"","code":"dist_paired_cols(dat)"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_paired_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dist_paired_cols — dist_paired_cols","text":"dat dataframe prepped using clean_2columns' word pairs arrayed two columns","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/dist_paired_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dist_paired_cols — dist_paired_cols","text":"dataframe","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_kmeans_clustersize.html","id":null,"dir":"Reference","previous_headings":"","what":"viz_kmeans_clustersize — viz_kmeans_clustersize","title":"viz_kmeans_clustersize — viz_kmeans_clustersize","text":"viz_kmeans_clustersize","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_kmeans_clustersize.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"viz_kmeans_clustersize — viz_kmeans_clustersize","text":"","code":"viz_kmeans_clustersize(distmat, k.max = 15, nboot = 150)"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_kmeans_clustersize.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"viz_kmeans_clustersize — viz_kmeans_clustersize","text":"distmat square matrix cosine dist values generated 'dist_matrix' function k.max maximum number clusters evaluate default 15 nboot number bootstrap samples determine gap statistic, default 150","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_kmeans_clustersize.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"viz_kmeans_clustersize — viz_kmeans_clustersize","text":"optimal_k integer (K) representing optimal cluster size distance matrix gap statistic","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_matrix2dendrogram.html","id":null,"dir":"Reference","previous_headings":"","what":"viz_matrix2dendrogram — viz_matrix2dendrogram","title":"viz_matrix2dendrogram — viz_matrix2dendrogram","text":"viz_matrix2dendrogram","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_matrix2dendrogram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"viz_matrix2dendrogram — viz_matrix2dendrogram","text":"","code":"viz_matrix2dendrogram(distmat)"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_matrix2dendrogram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"viz_matrix2dendrogram — viz_matrix2dendrogram","text":"distmat square matrix cosine dist values generated 'dist_matrix' function","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_matrix2dendrogram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"viz_matrix2dendrogram — viz_matrix2dendrogram","text":"plot dendrogram","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_monologue.html","id":null,"dir":"Reference","previous_headings":"","what":"viz_monologue — viz_monologue","title":"viz_monologue — viz_monologue","text":"viz_monologue","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_monologue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"viz_monologue — viz_monologue","text":"","code":"viz_monologue(   dat,   interpolate = TRUE,   roll_avg = 0,   facet = TRUE,   annotate = TRUE )"},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_monologue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"viz_monologue — viz_monologue","text":"dat dataframe semantic distance values columns (CosDist_) labeled 'row_id_postsplit' interpolate T/F linear interpolation across missing observations 'row_id_postsplit' (default T) roll_avg window computing rolling average smoothing data, default 0 (smoothing) facet T/F facets data distance measure (CosDist_Glo vs. CosDist_SD15) annotate T/F option annotating large semantic distance jumps z>2.5 red vertical line","code":""},{"path":"https://reilly-conceptscognitionlab.github.io/SemanticDistance/reference/viz_monologue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"viz_monologue — viz_monologue","text":"dataframe","code":""}]
