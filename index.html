<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Computes Pairwise Cosine Distance Between Successive Units of Language Samples • SemanticDistance</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Computes Pairwise Cosine Distance Between Successive Units of Language Samples">
<meta name="description" content="This package cleans and formats any user-specified language sample and appends two metrics of semantic distance (experiential and embedding) to each specified chunk (e.g., word-to-word, ngram-to-ngram, turn-to-turn). Users have several options for how to clean their data (e.g., leave it alone, lemmatize it, retain/omit stopwords). Users also have options for how to chunk distances. Options include word-to-word distance, ngram-to-ngram, sentence-to-sentence, turn-to-turn.">
<meta property="og:description" content="This package cleans and formats any user-specified language sample and appends two metrics of semantic distance (experiential and embedding) to each specified chunk (e.g., word-to-word, ngram-to-ngram, turn-to-turn). Users have several options for how to clean their data (e.g., leave it alone, lemmatize it, retain/omit stopwords). Users also have options for how to chunk distances. Options include word-to-word distance, ngram-to-ngram, sentence-to-sentence, turn-to-turn.">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">SemanticDistance</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="articles/SemanticDistance.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><p><img src="reference/figures/header4readme.png" alt="semantic relations between cat, dog, leash" width="45%"><br></p>
<!-- badges: start -->

<div class="section level2">
<h2 id="before-starting">Before Starting<a class="anchor" aria-label="anchor" href="#before-starting"></a>
</h2>
<p>SemanticDistance nominally requires a dataframe with at least one column variable and one row of text. The package is capable of processing many more dataframe formats (e.g., word pairs arrayed in columns, conversation transcripts, unordered word lists). SemanticDistance will retain all of your original metadata after splitting/unlisting your text into a one-word-per-row structure. This sequential structure is ideal for joining distance values to timestamps and other variables as language unfolds (e.g., reaction time, pupil diameter).</p>
</div>
<div class="section level2">
<h2 id="install--load">Install &amp; Load<a class="anchor" aria-label="anchor" href="#install--load"></a>
</h2>
<p>Install the development version of SemanticDistance from <a href="https://github.com/" class="external-link">GitHub</a> using devtools.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#install.packages("devtools")</span></span>
<span><span class="co">#devtools::install_github("Reilly-ConceptsCognitionLab/SemanticDistance")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance" class="external-link">SemanticDistance</a></span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="data-compatibility">Data Compatibility<a class="anchor" aria-label="anchor" href="#data-compatibility"></a>
</h2>
<p>Sometimes you care about computing time-ordered semantic distances between words in running discourse sampples. Other times word order doesn’t matter (e.g., using a simple machine learning algorithm to cluster a bag of words by similarity). Sometimes your data will be structured as monologues (e.g., stories, narratives). Other times you might be interested in computing semantic distance turn-by-turn across speakers in a conversation transcript (i.e., dialogue). The SemanticDistance pockage can handle all of these scenarios. However, is is important that <strong>you</strong> understand the structure of your data and what the distance measures mean.<br></p>
<p>Here are the formats SemanticDistance can currently handle: <br> 1. <strong>Monologues</strong>: A monologue transcript consists of any ordered text sample NOT delineated by a talker/speaker (e.g., stories, narratives). The minimal requirement for a monologue is one row and one column with some text in it.<br> 2. <strong>Dialogues</strong>: A dialogue transcript includes any sample split by talker/speaker/interlocutor information including conversation transcripts. The minimum requirment is two cells with interlocutor identity and text.<br> 3. <strong>Word Pairs in Columns</strong>: A dataframe that contains two columns of paired string data (col1 vs. col2). Calculates distance between each word pair across columns (e.g., Dog-Leash). <br> 4. <strong>Unordered Word Lists</strong>: A dataframe with an unordered list of words (nominally one column, all text in one row) that will be transformed into a distance matrix and hierarchically clustered <br></p>
</div>
<div class="section level2">
<h2 id="sample-language-transcripts-embedded-in-the-package">Sample language transcripts embedded in the package<a class="anchor" aria-label="anchor" href="#sample-language-transcripts-embedded-in-the-package"></a>
</h2>
<p>SemanticDistance contains some sample language transcripts that will automatically load when you call the package. These can be helpful for evaluating and debugging your own own data.<br></p>
<ol style="list-style-type: decimal">
<li>
<strong>Monologue_Structured:</strong> Dataframe 1-word per row already split no missing observations <br>
</li>
<li>
<strong>Monologue_Dirty:</strong> Dataframe text arrayed in one column ‘mytext’, missing observations, junk, multiword phrases contains metadata (simulated timestamps <br>
</li>
<li>
<strong>Monologue_VerbalFluency:</strong> Dataframe ordered simulated semantic fluency data switching between categories every ten words (animals, tools, musical instruments, fruits)</li>
<li>
<strong>Dialogue_Structured:</strong> Dataframe simulating ‘perfect’ conversation transcript, one word per turn, two talkers</li>
<li>
<strong>Dialogue_Dirty:</strong> Dataframe simulating ‘dirty’ conversation transcript, multiple lines per person, lots of stopwords, missing obervations, stray transcription symbols <br>
</li>
<li>
<strong>WordPairs_Columns:</strong> Dataframe with word pairs arrayed in two columns <br>
</li>
<li>
<strong>WordList_TestClustering:</strong> Unordered unsplit word list, some junk and also animal and weapon terms for hierachical clustering analysis <br><br>
</li>
</ol>
</div>
<div class="section level1">
<div class="page-header"><h1 id="step-1-cleaning-">
<span style="color: darkred;">—Step 1: Cleaning— </span><a class="anchor" aria-label="anchor" href="#step-1-cleaning-"></a>
</h1></div>
<p>First identify the type of data structure you want to process (e.g., monologue, dialogue, unordered list). The semantic distance functions work by indexing unique numeric identifiers. You <strong>MUST</strong> first clean/prep your raw text to append these identifers. Prepare your lexical data for computing pairwise semantic distances by first doing the following: <br> 1) Read your data into R. Label your text and metadata columns however you like. <br> 2) Your dataframe should contain at least one column with the target string data (e.g., mytext). <br> 3) Identify the format of your sample (e.g., monologue, dialogue, columns, unstructured). <br> 4) Decide on your cleaning parameters (lemmatize, omit stopwords, omit punctuation). <br> 5) Run the approproate cleaning function specifying the parameters that best fit your data and aims. <br><br></p>
<div class="section level2">
<h2 id="id_11-clean-monologue-transcript-clean_monologue">
<span style="color: brown;">1.1 Clean Monologue Transcript (clean_monologue)</span><a class="anchor" aria-label="anchor" href="#id_11-clean-monologue-transcript-clean_monologue"></a>
</h2>
<p>Clean a monologue transcript by calling the ‘clean_monologue’ function. Specific arguments include: <br></p>
<p><strong>df</strong> = raw dataframe with at least one column of text <br><strong>wordcol</strong> = quoted variable column name where your target text lives (e.g., ‘mytext’) <br><strong>clean</strong> = applies cleaning functions (e.g., punct out, lowercase, etc); default is TRUE <br><strong>omit_stops</strong> = omits stopwords, default is TRUE <br><strong>lemmatize</strong> = transforms raw word to lemmatized form, default is TRUE <br><strong>split_strings</strong> = T/F (default is T) option to split multiword utterances into separate rows <br></p>
<p>Output of ‘clean_monologue’ on a messy monologue transcript. Note that there are two ‘ID” variables appended. ’id_row_orig’ marks where your word was originally (pre-spitting) if you have rows with multi-word utterances. ‘id_row_postsplit’ marks a unique row ID after you have split contractions etc into a one-word-per-row format. Note that SemanticDistance requires a one word per row format. If you do not split strings, the program will squish all your separate strings in a row into one frankenword before moving on to compute distance, split_strings=F should only be used when you have already formatted your dataframe into a one word per row format and you absoluelty do not want to expand contractions or omit stopwords, etc.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#text in this dataframe is in a column 'mytext'</span></span>
<span><span class="va">MyCleanMonologue1</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/clean_monologue.html">clean_monologue</a></span><span class="op">(</span><span class="va">Monologue_Dirty</span>, wordcol<span class="op">=</span><span class="st">'mytext'</span>, clean<span class="op">=</span><span class="cn">T</span>, omit_stops<span class="op">=</span><span class="cn">T</span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: NLP</span></span>
<span><span class="co">#&gt; Loading required package: koRpus.lang.en</span></span>
<span><span class="co">#&gt; Loading required package: koRpus</span></span>
<span><span class="co">#&gt; Loading required package: sylly</span></span>
<span><span class="co">#&gt; For information on available language packages for 'koRpus', run</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;   available.koRpus.lang()</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; and see ?install.koRpus.lang()</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'koRpus'</span></span>
<span><span class="co">#&gt; The following object is masked from 'package:tm':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     readTagged</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'magrittr'</span></span>
<span><span class="co">#&gt; The following object is masked from 'package:tidyr':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     extract</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'dplyr'</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:stats':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     filter, lag</span></span>
<span><span class="co">#&gt; The following objects are masked from 'package:base':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     intersect, setdiff, setequal, union</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">MyCleanMonologue1</span>, n<span class="op">=</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 10 × 4</span></span>
<span><span class="co">#&gt;    id_row_orig word_clean mytext            id_row_postsplit</span></span>
<span><span class="co">#&gt;    &lt;fct&gt;       &lt;chr&gt;      &lt;chr&gt;                        &lt;int&gt;</span></span>
<span><span class="co">#&gt;  1 1           dog        The dog is blue.                 1</span></span>
<span><span class="co">#&gt;  2 1           blue       The dog is blue.                 2</span></span>
<span><span class="co">#&gt;  3 2           dog        Dog                              3</span></span>
<span><span class="co">#&gt;  4 3           dog        Dog                              4</span></span>
<span><span class="co">#&gt;  5 5           name       My name is Frank.                5</span></span>
<span><span class="co">#&gt;  6 5           frank      My name is Frank.                6</span></span>
<span><span class="co">#&gt;  7 6           dog        Dog                              7</span></span>
<span><span class="co">#&gt;  8 7           john       John's a jerk!                   8</span></span>
<span><span class="co">#&gt;  9 7           jerk       John's a jerk!                   9</span></span>
<span><span class="co">#&gt; 10 8           storm      Storm                           10</span></span></code></pre></div>
<p>Output of ‘clean_monologue’ on a structured monologue transcript</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#text in this dataframe is in a column 'mytext'</span></span>
<span><span class="va">MyCleanMonologue2</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/clean_monologue.html">clean_monologue</a></span><span class="op">(</span><span class="va">Monologue_Structured</span>, <span class="st">'mytext'</span>, clean<span class="op">=</span><span class="cn">T</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">MyCleanMonologue2</span>, n<span class="op">=</span><span class="fl">10</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 10 × 5</span></span>
<span><span class="co">#&gt;    id_row_orig word_clean timestamp mytext     id_row_postsplit</span></span>
<span><span class="co">#&gt;    &lt;fct&gt;       &lt;chr&gt;          &lt;int&gt; &lt;chr&gt;                 &lt;int&gt;</span></span>
<span><span class="co">#&gt;  1 2           girl               2 "girl"                    1</span></span>
<span><span class="co">#&gt;  2 3           walk               3 "walked"                  2</span></span>
<span><span class="co">#&gt;  3 4           down               4 "down "                   3</span></span>
<span><span class="co">#&gt;  4 6           street             6 "street"                  4</span></span>
<span><span class="co">#&gt;  5 8           boxer              8 "boxer"                   5</span></span>
<span><span class="co">#&gt;  6 9           punch              9 "punched"                 6</span></span>
<span><span class="co">#&gt;  7 11          wrestler          11 "wrestler"                7</span></span>
<span><span class="co">#&gt;  8 12          open              12 "open"                    8</span></span>
<span><span class="co">#&gt;  9 14          door              14 "door"                    9</span></span>
<span><span class="co">#&gt; 10 15          why               15 "why "                   10</span></span></code></pre></div>
<p><br></p>
</div>
<div class="section level2">
<h2 id="id_12-clean-dialogue-transcripts-clean_dialogue">
<span style="color: brown;">1.2 Clean Dialogue Transcripts (clean_dialogue)</span><a class="anchor" aria-label="anchor" href="#id_12-clean-dialogue-transcripts-clean_dialogue"></a>
</h2>
<p>This could be a conversation transcript or any language sample where you care about talker/interlocutor information (e.g., computing semantic distance across turns in a conversation). Your dataframe should nominally contain a text column and a speaker/talker column. Arguments clean_dialogue are: <br><strong>df</strong> = your raw dataframe with at least one column of text AND a talker column <br><strong>wordcol</strong> = column name (quoted) containing the text you want cleaned <br><strong>whotalks</strong> = column name (quoted) containing the talker ID (will convert to factor) <br><strong>clean</strong> = T/F (default is T) applies cleaning functions <br><strong>omit_stops</strong> = T/F omits stopwords, default is TRUE <br><strong>lemmatize</strong> = T/F transforms raw word to lemmatized form, default is TRUE <br></p>
<p>Output of ‘clean_dialogue’ prepping a well-structured dialogue transcript</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#My_CleanDialogue1 &lt;- clean_dialogue(Dialogue_Structured, "mytext", "speaker", omit_stops=T, lemmatize=T)</span></span>
<span><span class="co">#head(My_CleanDialogue1, n=8)</span></span></code></pre></div>
<p><br></p>
</div>
<div class="section level2">
<h2 id="id_13-clean-word-pairs-arrayed-in-columns-clean_2columns">
<span style="color: brown;">1.3 Clean Word Pairs Arrayed in Columns (clean_2columns)</span><a class="anchor" aria-label="anchor" href="#id_13-clean-word-pairs-arrayed-in-columns-clean_2columns"></a>
</h2>
<p>SemanticDistance also computes pairwise distance for data arrayed in columns. Run the function, the cleaned columns will appear in the dataframe. Arguments to the ‘clean_monologue’ function call are: <br></p>
<p><strong>df</strong> = your raw dataframe with at least one column of text <br><strong>word1</strong> = quoted variable reflecting the column name where your first word lives <br><strong>word2</strong> = quoted variable reflecting the column name where your first word lives <br><strong>clean</strong> = T/F (default is T) applies cleaning functions <br><strong>omit_stops</strong> = T/F omits stopwords, default is TRUE <br><strong>lemmatize</strong> = T/F transforms raw word to lemmatized form, default is TRUE <br></p>
<p>Output of ‘clean_2columns’ word pairs arrayed in columns</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">MyClean2Columns</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/clean_2cols.html">clean_2cols</a></span><span class="op">(</span><span class="va">WordPairs_Columns</span>, <span class="st">'word1'</span>, <span class="st">'word2'</span>, clean<span class="op">=</span><span class="cn">T</span>, omit_stops<span class="op">=</span><span class="cn">T</span>, lemmatize<span class="op">=</span><span class="cn">T</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">MyClean2Columns</span>, n<span class="op">=</span><span class="fl">8</span><span class="op">)</span> <span class="co">#view head cleaned data</span></span>
<span><span class="co">#&gt;   word1     word2 id_orig word1_clean word2_clean</span></span>
<span><span class="co">#&gt; 1   Dog   trumpet       1         dog     trumpet</span></span>
<span><span class="co">#&gt; 2   the    BANANA       2        &lt;NA&gt;      banana</span></span>
<span><span class="co">#&gt; 3   rat astronaut       3         rat   astronaut</span></span>
<span><span class="co">#&gt; 4  *&amp;^%    lizard       4        &lt;NA&gt;      lizard</span></span>
<span><span class="co">#&gt; 5  bird      bird       5        bird        bird</span></span>
<span><span class="co">#&gt; 6 shark     shark       6       shark       shark</span></span>
<span><span class="co">#&gt; 7 table     38947       7       table        &lt;NA&gt;</span></span>
<span><span class="co">#&gt; 8   Dog     leash       8         dog       leash</span></span></code></pre></div>
<p><br></p>
</div>
<div class="section level2">
<h2 id="id_14-clean-unordered-word-list-clean_unordered4matrix">
<span style="color: brown;">1.4 Clean Unordered Word List (clean_unordered4matrix)</span><a class="anchor" aria-label="anchor" href="#id_14-clean-unordered-word-list-clean_unordered4matrix"></a>
</h2>
<p>This cleaning option is used for prepping a vector of words for hierarchical clustering. Word order is no longer a factor since all words will be shuffled. This cleaning function retains only one instance of a word (no duplicates). Arguments to the ‘clean_unordered4matrix’ function call are: <br></p>
<p><strong>df</strong> = your raw dataframe with at least one column of text <br><strong>wordcol</strong> = quoted variable reflecting where your text lives <br><strong>clean</strong> = T/F (default is T) applies cleaning functions <br><strong>omit_stops</strong> = T/F omits stopwords, default is TRUE <br><strong>lemmatize</strong> = T/F transforms raw word to lemmatized form, default is TRUE <br></p>
<p>Output of ‘clean_unordered4matrix’ on unordered word list</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Run clean fn </span></span>
<span><span class="va">MyCleanDat4Matrix</span> <span class="op">&lt;-</span> <span class="fu">clean_unordered4matrix</span><span class="op">(</span><span class="va">WordList_TestClustering</span>, wordcol<span class="op">=</span><span class="st">"mytext"</span>, clean<span class="op">=</span><span class="cn">TRUE</span>, omit_stops<span class="op">=</span><span class="cn">TRUE</span>, lemmatize<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">MyCleanDat4Matrix</span><span class="op">)</span></span>
<span><span class="co">#&gt; # A tibble: 1 × 3</span></span>
<span><span class="co">#&gt;   mytext                                                      id_orig word_clean</span></span>
<span><span class="co">#&gt;   &lt;chr&gt;                                                         &lt;int&gt; &lt;chr&gt;     </span></span>
<span><span class="co">#&gt; 1 dog cat $ Rat gun banana the sword table glasses phone sof…       1 dogcatrat…</span></span></code></pre></div>
<p><br><br></p>
</div>
</div>
<div class="section level1">
<h1 id="step-2-compute-semantic-distance">
<span style="color: darkred;">–Step 2: Compute Semantic Distance–</span><a class="anchor" aria-label="anchor" href="#step-2-compute-semantic-distance"></a>
</h1>
<p>SemanticDistance will append cosine distance values between each pair of elements specified by the user (e.g., word-to-word, ngram-to-word). These distance values are derived from two large lookup databases in the package with fixed semantic vectors for &gt;70k English words. CosDist_Glo reflects cosine distance between vectors derived from training a GLOVE word embedding model (300 hyperparameters per word). CodDist_SD15 refects cosine distance between two chunks (words, groups of words) characterized across 15 meaningful perceptual and affective dimensions (e.g., color, sound, valence). <br><br></p>
<div class="section level2">
<h2 id="id_21-compute-ngram-to-word-distance-dist_ngram2word">
<span style="color: brown;">2.1: Compute Ngram-to-Word Distance (dist_ngram2word)</span><a class="anchor" aria-label="anchor" href="#id_21-compute-ngram-to-word-distance-dist_ngram2word"></a>
</h2>
<p>Computes cosine distance for two models (embedding and experiential) using a rolling ngram approach consisting of groups of words (ngrams) to the next word. <em>IMPORTANT</em> the way this works is that the function rolls backward from the target word skipping over NAs until filling the desired ngram size. It does not do the same procedure for filling forward. If you evaluate a row with an NA it will look backward until finding n real words and then produce an NA when trying to compare the ngram to the target word (because there is no target word for that row).</p>
<p><img src="reference/figures/RollingNgramIllustrate.png" alt="illustrates how rolling ngrams work on a vector of words by moving a window and contrasting each chunk to each new word" width="50%"><br><br></p>
<p>Remember to call a cleaned/prepped dataframe! Arguments to ‘dist_ngram2word’ are: <br> | <strong>dat</strong> dataframe of a monologue transcript cleaned and prepped with clean_monologue fn <br> | <strong>ngram</strong> window size preceding each new content word <br></p>
<p>Output ‘dist_ngram2word’ on a messy monologue</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Set the ngram=1, distance every word to the next word</span></span>
<span><span class="co">#MyNgram2WordDists1 &lt;- dist_ngram2word(MyCleanMonologue1, ngram=1) #distance word-to-word</span></span>
<span><span class="co">#head(MyNgram2WordDists1, n=8)</span></span></code></pre></div>
<p>Output ‘dist_ngram2word’ on a well-structured monologue</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Set the ngram=3, distance rolling chunks of 3 words to the next word</span></span>
<span><span class="co">#MyNgram2WordDists2 &lt;- dist_ngram2word(MyCleanMonologue2, ngram=3) #distance word-to-word</span></span>
<span><span class="co">#head(MyNgram2WordDists2, n=12)</span></span></code></pre></div>
<p><br></p>
</div>
<div class="section level2">
<h2 id="id_22-compute-ngram-to-ngram-distance-dist_ngram2ngram">
<span style="color: brown;">2.2: Compute Ngram-to-Ngram Distance (dist_ngram2ngram)</span><a class="anchor" aria-label="anchor" href="#id_22-compute-ngram-to-ngram-distance-dist_ngram2ngram"></a>
</h2>
<p>User specifies n-gram size (e.g., ngram=2). Distance computed from each two-word chunk to the next iterating all the way down the dataframe until there are no more words to ‘fill out’ the last ngram. <br></p>
<p><img src="reference/figures/Ngram2Ngram_Dist.png" alt="semantic distance is derived from chunk to chunk groupings of words" width="50%"><br></p>
<p>Arguments to dist_ngram2ngram are: <br> | dat = dataframe w/ a monologue sample cleaned and prepped <br> | ngram = chunk size (chunk-to-chunk) <br></p>
<p>Output ‘dist_ngram2ngram’ on monologue transcript</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Give the function a cleaned monologue transcript, This example involves chunks of 2-words to 2-words</span></span>
<span><span class="co">#MyNgram2NgramDists &lt;- dist_ngram2ngram(MyCleanMonologue2, ngram=2)</span></span>
<span><span class="co">#head(MyNgram2NgramDists, n=8)</span></span></code></pre></div>
<p><br></p>
</div>
<div class="section level2">
<h2 id="id_23-compute-turn-by-turn-distance-dist_dialogue_turns">
<span style="color: brown;">2.3: Compute Turn-by-Turn Distance (dist_dialogue_turns)</span><a class="anchor" aria-label="anchor" href="#id_23-compute-turn-by-turn-distance-dist_dialogue_turns"></a>
</h2>
<p>Averages the semantic vectors for all content words in a turn. Computes the cosine distance to the average of the semantic vectors of the content words in the subsequent turn. <br></p>
<p>Arguments to ‘dist_dialogue_turns’ are: <br><strong>dat</strong> = dataframe w/ a dialogue sample cleaned and prepped using ‘clean_dialogue’ fn<br></p>
<p>Output of ‘dist_dialogue_turns’ turn-to-turn distance on sample dialogue transcript</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#MyDialogueDists &lt;- dist_dialogue_turns(MyCleanDialogue)</span></span>
<span><span class="co">#head(MyDialogueDists, n=15)</span></span></code></pre></div>
<p><br></p>
</div>
<div class="section level2">
<h2 id="id_24-compute-distances-between-word-pairs-in-columns-dist_2cols">
<span style="color: brown;">2.4: Compute Distances Between Word Pairs in Columns (dist_2cols)</span><a class="anchor" aria-label="anchor" href="#id_24-compute-distances-between-word-pairs-in-columns-dist_2cols"></a>
</h2>
<p>When your data are arrayed in two columns and you are interested in computing pairwise distance across the columns. The only critical argument is your dataframe name. Remember to pass a cleaned dataframe (even if you disable stopwords and lemmatization). Arguments to the function: <br> | dat = your cleaned dataframe with two paired columns of text <br></p>
<p>Arguments to ‘dist_2cols’ are: <br><strong>dat</strong> = dataframe w/ word pairs arrayed in columns cleaned and prepped using ‘clean_2cols’ fn<br></p>
<p>Output of ‘dist_2cols’ on 2-column arrayed dataframe</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#MyDistsColumns &lt;- dist_2cols(MyClean2Columns) #only argument is dataframe</span></span>
<span><span class="co">#head(MyDistsColumns, n=8)</span></span></code></pre></div>
<p><br></p>
</div>
<div class="section level2">
<h2 id="id_25-distance-fixed-cluster-of-words-to-each-new-word-anchor_dist">
<span style="color: brown;">2.5: Distance Fixed Cluster of Words to each new word (anchor_dist)</span><a class="anchor" aria-label="anchor" href="#id_25-distance-fixed-cluster-of-words-to-each-new-word-anchor_dist"></a>
</h2>
<p>Models semantic distance from each successive new word in a language sample to the average of the semantic vectors for the first block of N content words in that sample. This anchored distance provides a metric of overall semantic drift as a language sample unfolds relative to a fixed starting point.<br></p>
<p>Arguments to ‘anchor_dist’ are: <br><strong>dat</strong> = dataframe w/ a monologue sample cleaned and prepped using ‘clean_monologue’ fn<br><strong>anchor_size</strong> = size of the initial chunk of words for chunk-to-new-word comparisons fn<br></p>
<p><img src="reference/figures/Anchor_2Word_Dist.png" alt="illustrates distance from each new word of a language sample to an initial chunk of n-words" width="80%"></p>
<p>Output of ‘anchor_dist’ on a sample monologue transcript</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#MyDistsAnchored &lt;- dist_anchor(MyCleanMonologue2, anchor_size=8)</span></span>
<span><span class="co">#head(MyDistsAnchored, n=10)</span></span></code></pre></div>
<p><br></p>
</div>
<div class="section level2">
<h2 id="id_26-distance-matrix-all-word-pairs-dist_matrix_all">
<span style="color: brown;">2.6: Distance Matrix All Word Pairs (dist_matrix_all)</span><a class="anchor" aria-label="anchor" href="#id_26-distance-matrix-all-word-pairs-dist_matrix_all"></a>
</h2>
<p>Returns square matrix where each entry [i,j] is the cosine distance between word i and word j. Matrix contains original words as both row and column names for reference. User specifies whether to return a matrix based on embeddings (GLOVE) or experiential norms (SD15). Input a unordered vector of words cleaned/prepped with ‘clean_unordered4matrix’ function <br></p>
<p>Arguments to ‘dist_matrix_all’ are: <br><strong>dat</strong> = dataframe cleaned and prepped using ‘clean_unordered4matrix’ fn<br><strong>dist_type</strong> = quoted argument default is ‘embedding’, other option is “SD15” fn<br></p>
<p>Output of ‘dist_unordered’ on unordered word list</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">MyDistMatrix</span> <span class="op">&lt;-</span> <span class="fu">dist_matrix_all</span><span class="op">(</span><span class="va">MyCleanDat4Matrix</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">MyDistMatrix</span><span class="op">)</span></span>
<span><span class="co">#&gt;                                                                                                    dogcatratgunbananaswordtableglassesphonesofamissilelambrifletrumpetpianochairdesksnakedolphinshark</span></span>
<span><span class="co">#&gt; dogcatratgunbananaswordtableglassesphonesofamissilelambrifletrumpetpianochairdesksnakedolphinshark                                                                                                 NA</span></span></code></pre></div>
<p><br><br></p>
</div>
</div>
<div class="section level1">
<h1 id="step-3-data-visualization-options">
<span style="color: darkred;">—Step 3: Data Visualization Options—</span><a class="anchor" aria-label="anchor" href="#step-3-data-visualization-options"></a>
</h1>
<div class="section level2">
<h2 id="monologue-time-series-ngram2word">Monologue Time Series: ngram2word<a class="anchor" aria-label="anchor" href="#monologue-time-series-ngram2word"></a>
</h2>
<p>Plots id_orig (as x-axis time) by distance measure (facetted GLO and SD15). Add red line annotation if semantic distance jump is z&gt;3 based on the distribution of that time series</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Select id_orig, "CosDist_Glo", "CosDist_SD15", pivot_longer</span></span>
<span><span class="co">#add smoothing options</span></span>
<span><span class="co">#Argument annotate=T, adds red line whenever semantic distance jump is z&gt;3</span></span>
<span><span class="co">#linear interpolation using zoo, necessary for geom_path to complete</span></span>
<span><span class="co">#pivots on any/all cos_dist columns</span></span>
<span><span class="co">#facets on any/all cos_dist columns</span></span>
<span><span class="co">#scale axis 0 to 1.5</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="monologue-time-series-anchor2word">Monologue Time Series: anchor2word<a class="anchor" aria-label="anchor" href="#monologue-time-series-anchor2word"></a>
</h2>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#TBA</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="time-series-plot-for-dialogues">Time series plot for dialogues<a class="anchor" aria-label="anchor" href="#time-series-plot-for-dialogues"></a>
</h2>
<p>Color point by talker</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#TBA</span></span></code></pre></div>
<p>#Animate Time Series</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#TBA</span></span></code></pre></div>
</div>
</div>

  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small>GPL (&gt;= 3)</small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing SemanticDistance</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Jamie Reilly <br><small class="roles"> Author, maintainer </small>   </li>
<li>Hannah Mechtenberg <br><small class="roles"> Author </small>   </li>
<li>Emily Myers <br><small class="roles"> Author </small>   </li>
<li>Jonathan Peelle <br><small class="roles"> Author </small>   </li>
</ul>
</div>

<div class="dev-status">
<h2 data-toc-skip>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/actions/workflows/R-CMD-check.yaml" class="external-link"><img src="https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/actions/workflows/R-CMD-check.yaml/badge.svg" alt="R-CMD-check"></a></li>
</ul>
</div>

  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Jamie Reilly, Hannah Mechtenberg, Emily Myers, Jonathan Peelle.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer>
</div>





  </body>
</html>
