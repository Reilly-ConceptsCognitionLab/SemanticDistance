---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# SemanticDistance

<img src="man/figures/header4readme.png" alt="semantic relations between cat, dog, leash" width="40%" />

<!-- badges: start -->
[![R-CMD-check](https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/Reilly-ConceptsCognitionLab/SemanticDistance/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

SemanticDistance cleans and formats text then computes pairwise metrics of cosine semantic distance between different adjacent chunks (e.g., ngrams, words, turns) within language samples. We offer two different semantic distance metrics, experiential and embedding. Experiential semantic distance reflects cosine (normalized from 0) between two vectors spanning 15 meaningful semantic dimensions (e.g., color, sound, valence). Embedding-based semantic distances are derived by contrasting each word's corresponding semantic vector spanning 300 hyperparameters as trained on the GLOVE word embedding model. The SemamticDistance package contains lookup databases with semantic vectors spanning >70k English words. <br/>

SemanticDistance operates on a dataframe that nominally has one column of text that has been split into a one word-per-row format. However, SemanticDistance can also produce distance values for words arrayed in two columns. Users have numerous 'chunking' options for rolling distance comparisons in either monologues (no speaker information) or dialogues (speakers identifed as in conversation transcripts). Chunk options include: <br/>
1) word-to-word <br/>
2) ngram-to-ngram <br/>
3) ngram-to-word (rolling) <br/>
4) turn-to-turn (split by talker ID) <br/>

## Installation

You can install the development version of SemanticDistance from [GitHub](https://github.com/) with:

``` r
install.packages("devtools")
devtools::install_github("Reilly-ConceptsCognitionLab/ConversationAlign")
```

You will nominally need one column of text within a dataframe. Your text should be pre-formatted so that it is split into a one word per row format. However, SemanticDistance is also capable of computing   pairwise cosine distance across two columns  (e.g., dog leash).

# Let's do it!
Pre-format your language transcript. SemanticDistance works on monologues (no talker information) or dialogues (two or more speakers). First load the package. Then read your transcript into R. It doesn't matter how you label your variables. You will specify these names in the arguments to your function calls. The first critical step is to clean and format your transcript. There are three cleaning functions to choose from based on the structure of your data:  clean_monologue, clean_dialogue, clean_columns <br/>

## load the package
```{r example}
library(SemanticDistance)
```

## View raw data
### monologue
This could be a story or instructions - anything where you don't care about talker information. You should format your transcript so that there is a vector (column) of words. All other metadata will be retained. Here's a sample monologue with all sorts of junk in a column called 'mytext'. It's not split and vectorized the way it should be, but the clean_monologue function should fix it and append a unique identifier to each word while retaining empty strings that could be meaningful.
```{r}
#raw messy transcript of a monologue with missing obs and text that needs to be split
head(MonologueSample1, n=25)
```

### clean_monologue
Appends a unique numeric identifier to each row. Then splits all the elenents of each row into separate rows. Defaults are to omit stopwords and lemmatize. Note: if you want to lemmatize and omit stopwords you don't need to do anything or specify the arguments. You do, however, need to tell the package your dataframe name and the column name (in quotes) you want to run your operation on,
```{r}
#arguments: df, wordcol, omit_stops=TRUE, lemmatize = TRUE
#df=dataframe name 
#wordcol = quoted column name where your text data live
#omit_stops - omit stopwords default is TRUE
#lemnatize - lemmatizes strings default is TRUE
my_clean_dat <- clean_monologue(MonologueSample1, 'word', omit_stops=T, lemmatize=T)
```


